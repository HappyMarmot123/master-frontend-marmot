# 🤖 AI 제품 프론트엔드 개발 가이드라인

AI 제품의 프론트엔드 개발은 비동기 데이터 스트림과 동적 UI 변화에 최적화되어야 합니다. 일반적인 웹 개발을 넘어선 실시간성, 사용자 경험(UX), 그리고 예측 불가능한 AI 출력을 관리하는 것이 핵심입니다.

## 1. 스트리밍 데이터 처리 및 제너레이터 구현

LLM 응답은 REST API의 단일 응답이 아닌, 서버-센트 이벤트(SSE)나 웹소켓(WebSocket)을 통한 스트림 형태로 전달됩니다. 프론트엔드는 이를 효율적으로 수신하고 처리해야 합니다.

### 1.1. 비동기 데이터 수신

| 항목                | 설명                                                                                                                                              | 구현 전략                                                                                                                           |
| :------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------- |
| **API 통신**        | LLM 서버와의 통신은 주로 `fetch` API를 사용하여 스트림을 열거나, SSE/WebSocket 클라이언트 라이브러리를 사용합니다.                                | JavaScript의 **`ReadableStream`** 및 **`TextDecoder`**를 사용하여 바이트 스트림을 문자열로 디코딩하고 청크를 순차적으로 처리합니다. |
| **제너레이터 패턴** | 서버에서 `yield`되는 데이터 청크를 클라이언트에서 **`async/await`** 및 **`for-await-of`** 루프를 사용하여 소비합니다.                             | `while (true)` 루프 내에서 `reader.read()`를 호출하여 스트림이 종료될 때(`done: true`)까지 데이터를 지속적으로 읽습니다.            |
| **스트림 파싱**     | 하나의 네트워크 패킷에 여러 청크가 섞여 들어올 수 있으므로, 청크를 의미 있는 **완전한 메시지 단위**로 분리하고 파싱하는 로직을 필수로 구현합니다. | 일반적으로 `data: {json}` 형식의 SSE 프로토콜을 따르며, 줄 바꿈 문자(`\n\n`)를 기준으로 메시지를 분리합니다.                        |

### 1.2. 스트리밍 제어 및 안정성

| 항목                         | 설명                                                                                                          | 코드 스니펫 예시                                                                                                 |
| :--------------------------- | :------------------------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------- |
| **생성 중단 (Cancellation)** | 사용자가 중간에 응답 생성을 취소할 수 있도록 `AbortController`를 사용하여 요청을 취소합니다.                  | `const controller = new AbortController();` / `fetch(url, { signal: controller.signal })`                        |
| **오류 처리**                | 스트림 도중 네트워크 오류, 타임아웃, 서버 측 에러가 발생하면 연결을 즉시 닫고 사용자에게 피드백을 제공합니다. | `try...catch` 블록을 사용하여 `reader.read()` 과정의 예외를 처리하고 `controller.abort()`를 호출하여 정리합니다. |

## 2. UI/UX 최적화 및 동적 렌더링

스트리밍 환경에서 사용자 경험을 극대화하고, 다양한 AI 출력 형식을 시각적으로 처리해야 합니다.

### 2.1. 실시간 렌더링 최적화

- **타이핑 효과(Typewriter Effect):** 수신된 텍스트를 DOM에 즉시 추가하여 모델이 '작성 중'이라는 인식을 주어 체감 대기 시간을 줄입니다. (`innerHTML`보다는 `textContent` 또는 프레임워크의 상태 관리 기능을 사용하여 효율적으로 업데이트합니다.)
- **스크롤 관리:** 새로운 콘텐츠가 추가될 때마다 사용자 뷰포트를 답변의 최하단으로 부드럽게 이동시키는 자동 스크롤(Auto-Scroll) 기능을 구현합니다. (단, 사용자가 수동으로 스크롤한 경우 자동 스크롤을 일시 정지하여 독서 흐름을 방해하지 않아야 합니다.)
- **리렌더링 최소화:** React 등 SPA 프레임워크에서 매 청크마다 전체 컴포넌트가 리렌더링되지 않도록 `memo`나 `useMemo`를 사용하여 렌더링 범위를 최소화합니다.

### 2.2. 출력 형식에 따른 UI 변환

LLM의 출력은 비정형 텍스트 외에도 구조화된 데이터를 포함하므로, 이에 맞는 적절한 UI 처리가 필수적입니다.

| 출력 유형          | 처리 전략                                                                                                                                     | 구현 라이브러리 예시                                |
| :----------------- | :-------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------- |
| **마크다운**       | 텍스트 내의 `#`, `*`, `` ` `` 등을 파싱하여 제목, 리스트, 표, 코드 블록으로 변환합니다.                                                       | `react-markdown`, `marked.js` 등 마크다운 파서 사용 |
| **코드 블록**      | 마크다운 내의 코드 블록(` ```python `)을 인식하여 언어별 **구문 강조(Syntax Highlighting)**를 적용하고, **복사 버튼**을 통합합니다.           | `react-syntax-highlighter`, `Prism.js`              |
| **JSON/YAML**      | LLM에게 특정 형식으로 답변을 요청했을 경우, 출력된 문자열을 파싱하여 **구조화된 뷰어(Tree View)**나 편집기 형태로 표시하여 가독성을 높입니다. |
| **중간 상태/로딩** | 답변이 시작되기 전이나 처리 중에는 "AI Thinking..." 같은 명확한 메시지 또는 **타이핑 애니메이션**을 표시합니다.                               |

## 3. 상호작용 및 피드백 루프

사용자에게 AI와의 상호작용에 대한 통제권을 부여하고, 모델 개선에 필요한 데이터를 수집합니다.

- **사용자 피드백 (Rating):** 모든 답변 끝에 "좋아요/싫어요" 또는 별점 시스템을 통합하여 사용자가 답변 품질을 즉시 평가하도록 유도합니다. 이 데이터는 LLM을 미세 조정(Fine-tuning)하는 데 귀중한 자료가 됩니다.
- **입력 검증 및 경고:** 프롬프트가 서비스 정책을 위반하거나 너무 길어질 경우, 서버 요청 전에 **프론트엔드에서 경고**를 표시하여 불필요한 API 호출을 방지합니다.
- **히스토리 관리:** 세션이 종료된 후에도 사용자의 대화 기록(프롬프트와 답변 쌍)을 안전하게 저장하고, 이를 통해 과거 컨텍스트를 참조하여 새로운 질문에 답변할 수 있도록 준비합니다.
