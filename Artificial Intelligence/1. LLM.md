## 1. LLM 개요 및 배경

### LLM이란 무엇인가?

LLM(Large Language Model, 거대 언어 모델)은 방대한 양의 텍스트 데이터를 학습하여 인간의 언어를 이해하고 생성할 수 있는 인공지능 모델이다. "Large"라는 표현은 모델의 파라미터 수가 수십억에서 수천억 개에 달한다는 것을 의미하며, 이러한 규모 덕분에 복잡한 언어 패턴을 학습할 수 있다.

LLM의 핵심 원리는 놀랍도록 단순하다. 주어진 텍스트 시퀀스에서 다음에 올 단어(토큰)를 예측하는 것이다. 예를 들어 "오늘 날씨가 정말"이라는 문장이 주어지면, 모델은 "좋다", "덥다", "춥다" 등 문맥상 적절한 단어를 확률적으로 예측한다. 이 단순한 원리가 반복되면서 문장이 생성되고, 충분히 큰 모델과 데이터로 학습하면 놀라운 수준의 언어 이해와 생성 능력이 발현된다.

### 기존 머신러닝과의 차이점

전통적인 머신러닝과 LLM을 포함한 딥러닝의 가장 큰 차이점은 특징 추출(Feature Extraction) 방식에 있다.

머신러닝에서는 도메인 전문가가 직접 데이터에서 의미 있는 특징을 정의하고 추출해야 한다. 예를 들어 스팸 메일을 분류한다면, "특정 단어의 출현 빈도", "링크 개수" 등을 사람이 직접 정의해서 모델에 입력한다. 반면 딥러닝은 **특징 추출과 분류를 함께 학습**한다. 원시 데이터(raw data)를 그대로 입력받아 여러 층의 신경망을 통과시킨다. 텍스트에서는 문법, 의미, 맥락을 스스로 파악한다. 사람의 개입 없이 데이터로부터 직접 학습하기 때문에, 복잡한 패턴까지 포착할 수 있다.

## 2. 딥러닝 기초

딥러닝은 인공 신경망(Artificial Neural Network)을 여러 층으로 깊게 쌓아 복잡한 패턴을 학습하는 머신러닝의 한 분야다. 일반적으로 3개 이상의 은닉층을 가진다. 딥러닝의 핵심 특징은 계층적 특징 학습이다. 초기 층에서는 단순한 패턴을 인식하고, 깊어질수록 추상적인 개념을 파악한다.

데이터는 크게 정형 데이터와 비정형 데이터로 나뉜다.

**정형 데이터**는 행과 열로 구성된 테이블 형태의 데이터다. 엑셀 스프레드시트, 관계형 데이터베이스의 테이블이 대표적이다. 전통적인 머신러닝 알고리즘이 잘 작동한다.
**비정형 데이터**는 고정된 구조가 없는 데이터다. 텍스트, 이미지, 오디오, 비디오 등이 여기에 속한다. 

딥러닝의 혁신적인 점은 **비정형 데이터에서 뛰어난 패턴 인식 성능**을 보인다는 것이다. 이미지에서 고양이를 인식하고, 음성에서 단어를 추출하고, 텍스트에서 감정을 분석하는 작업을 사람 수준으로 수행할 수 있게 되었다. LLM은 특히 텍스트라는 비정형 데이터를 다루는 데 특화되어 있다.

### 딥러닝의 문제 해결 과정

딥러닝으로 문제를 해결하는 과정은 다음과 같이 진행된다.

첫째, 문제 유형에 맞는 모델을 준비한다. 자연어 처리에는 Transformer 기반 모델을 사용한다.  
둘째, 학습 데이터를 준비한다. 딥러닝의 성능은 데이터의 양과 질에 크게 의존한다. 데이터가 많을수록, 다양할수록 모델이 더 일반화된 패턴을 학습한다. 데이터 전처리, 정제, 증강 작업이 이 단계에 포함된다.  
셋째, 학습 데이터를 반복적으로 모델에 입력하며 학습한다. 이 과정을 수천, 수만 번 반복하면서 모델의 성능이 점진적으로 향상된다.  

## 3. 전이학습 (Transfer Learning)

전이학습은 한 문제를 해결하면서 얻은 지식을 다른 문제에 활용하는 방식이다. 마치 피아노를 배운 사람이 다른 건반 악기를 더 쉽게 배우는 것과 같다. 악보 읽기 능력이 전이되기 때문이다. 딥러닝에서 전이학습은 특히 중요하다. 방대한 컴퓨팅 자원 없이도 이미 학습된 모델의 지식을 활용하면, 적은 데이터와 자원으로도 좋은 성능을 얻을 수 있다. 전이학습은 사전학습(Pre-training)과 미세조정(Fine-tuning)이라는 두 단계로 구성된다.

사전학습은 대규모 데이터셋으로 모델의 기본적인 표현 능력을 학습시키는 단계다. LLM의 경우, 인터넷에서 수집한 수십억 개의 문장을 사용하여 "다음 단어 예측" 과제를 수행한다. 이 과정에서 모델은 문법, 어휘, 상식, 추론 능력 등 언어에 대한 광범위한 지식을 습득한다.

미세조정은 사전학습된 모델을 특정 작업이나 도메인에 맞게 추가 학습시키는 단계다. 사전학습에서 습득한 일반적인 언어 지식을 기반으로, 목표 작업에 필요한 세부적인 패턴을 학습한다.

예를 들어 법률 문서를 분석하는 시스템을 만든다면, 일반 텍스트로 사전학습된 모델에 법률 문서 데이터셋으로 미세조정을 수행한다. 모델은 기본적인 언어 능력은 유지하면서, 법률 용어와 문서 구조에 대한 이해를 추가로 습득한다. 미세조정의 장점은 적은 데이터로도 효과적이라는 점이다. 사전학습에서 이미 언어의 기본 구조를 학습했기 때문에, 수천 개 정도의 예제만으로도 특정 작업에서 좋은 성능을 낼 수 있다.


## 4. 멀티모달 (Multimodal)

초기 AI 모델들은 단일 모달리티만 처리했다. 이미지 인식 모델은 이미지만, 음성 인식 모델은 음성만, 언어 모델은 텍스트만 다루었다. 하지만 멀티모달 AI는 이러한 경계를 넘어 텍스트, 이미지, 음성, 비디오 등을 동시에 입력받고 출력할 수 있다.

멀티모달 모델의 입출력은 다양한 조합이 가능하다.

**텍스트 → 이미지**: 텍스트 설명을 바탕으로 이미지를 생성한다. "석양 아래 해변에서 뛰어노는 강아지"라고 입력하면, 해당 장면의 이미지가 생성된다. DALL-E, Midjourney, Stable Diffusion 등이 대표적이다.  
**이미지 → 텍스트**: 이미지를 분석하여 텍스트로 설명한다. 사진을 보여주고 "이 이미지에 무엇이 있나요?"라고 물으면, 이미지의 내용을 자연어로 설명한다. 시각 장애인을 위한 이미지 설명, 자동 캡션 생성 등에 활용된다.  

### Vision-Language 모델

Vision-Language 모델은 시각(Vision)과 언어를 통합한 멀티모달 모델의 대표적인 유형이다. GPT-4V(Vision), Claude의 이미지 이해 기능, Google의 Gemini 등이 여기에 속한다. 이러한 모델들은 이미지 인코더와 언어 모델을 결합한 구조를 가진다. 이미지 인코더가 시각적 정보를 벡터로 변환하면, 이를 언어 모델이 이해할 수 있는 형태로 투영하여 함께 처리한다. 결과적으로 "이 사진에서 고양이가 무엇을 하고 있나요?"와 같은 질문에 자연스럽게 답할 수 있다.  

## 5. AI 에이전트 (Agent)

기존의 LLM은 주로 "입력 → 출력"의 단방향 상호작용에 머물렀다. 사용자가 질문하면 답하고, 요청하면 텍스트를 생성하는 식이다. 하지만 에이전트는 **환경과 상호작용하며 능동적으로 행동**한다. 주어진 목표를 달성하기 위해 자율적으로 계획하고, 의사결정을 내리는 시스템이다.

### 에이전트의 핵심 요소

에이전트는 크게 세 가지 핵심 능력을 갖추어야 한다.

**계획(Planning)**: 복잡한 목표를 달성 가능한 하위 작업들로 분해한다. "내일 서울 여행 일정을 짜줘"라는 요청을 받으면, 날씨 확인, 관광지 검색, 식당 예약, 교통편 조회 등의 세부 작업으로 나눈다. 작업 간의 의존성을 파악하고 적절한 순서를 결정한다.  
**의사결정(Decision Making)**: 각 단계에서 어떤 행동을 취할지, 어떤 도구를 사용할지 판단한다. 여러 선택지 중에서 목표 달성에 가장 효과적인 것을 선택한다. 예상치 못한 상황(오류, 실패)에 대응하여 대안을 찾기도 한다.  
**행동 수행(Action Execution)**: 실제로 외부 시스템과 상호작용하여 작업을 수행한다. 검색 엔진에 쿼리를 보내고, 데이터베이스를 조회하고, 이메일을 발송하는 등의 구체적인 행동을 취한다. 행동의 결과를 관찰하고, 이를 다음 의사결정에 반영한다.  

### LLM 기반 에이전트의 구성

LLM 기반 에이전트는 일반적으로 다음 구성요소로 이루어진다.

**두뇌(Brain)**: LLM이 에이전트의 핵심 추론 엔진 역할을 한다. 상황을 이해하고, 계획을 세우며, 어떤 도구를 언제 사용할지 결정한다.  
**도구(Tools)**: 에이전트가 실제로 행동할 수 있게 하는 외부 기능들이다. 웹 검색, 코드 실행, 파일 시스템 접근, API 호출 등이 도구가 될 수 있다. 도구는 LLM이 직접 수행할 수 없는 작업을 대신한다.  
**메모리(Memory)**: 대화 기록, 수행한 작업, 얻은 정보 등을 저장한다. 단기 메모리는 현재 세션의 맥락을 유지하고, 장기 메모리는 이전 상호작용에서 학습한 정보를 보존한다.  
**프롬프트(Prompt)**: 에이전트의 역할, 사용 가능한 도구, 행동 지침 등을 정의한다. 에이전트가 어떤 방식으로 사고하고 행동할지를 결정하는 "성격"과 같다.  

## 6. 오케스트레이션 도구

에이전트를 구축하려면 LLM, 도구, 메모리 등 여러 구성요소를 연결하고 조율해야 한다. 이를 돕는 오케스트레이션 프레임워크가 있다. 이러한 도구들은 에이전트 개발의 진입 장벽을 낮추고, UI, 임베딩 모델, 벡터 DB 등 LLM 애플리케이션의 구성요소를 손쉽게 연결할 수 있게 한다.

**LangChain**은 가장 널리 사용되는 LLM 오케스트레이션 도구다. 다양한 LLM 프로바이더, 벡터 데이터베이스, 도구들을 통합된 인터페이스로 연결한다. 체인(Chain)이라는 개념을 통해 여러 LLM 호출과 도구 사용을 순차적 또는 조건부로 연결할 수 있다. 에이전트 구축을 위한 템플릿과 추상화를 제공한다.  
**LlamaIndex**는 특히 데이터 연결에 특화된 프레임워크다. 다양한 형식의 문서(PDF, HTML, 데이터베이스 등)를 LLM이 활용할 수 있는 형태로 인덱싱하고 검색하는 기능을 제공한다. RAG(Retrieval-Augmented Generation) 시스템 구축에 많이 사용된다.  

