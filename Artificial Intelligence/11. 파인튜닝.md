# 파인튜닝 (Fine-tuning)

파인튜닝은 사전 훈련된(Pre-trained) 대규모 언어 모델을 특정 작업이나 도메인에 맞게 조정하는 과정입니다. 모델의 전체 가중치(Weight)를 미세하게 조정하여, 원래의 일반적인 능력은 유지하면서 특정 작업에서의 성능을 크게 향상시킵니다.

### 왜 파인튜닝이 필요한가?

대규모 언어 모델은 방대한 양의 일반적인 텍스트 데이터로 학습되어 있어, 다양한 주제에 대해 어느 정도의 지식과 이해를 가지고 있습니다. 하지만 특정 도메인이나 작업에 집중할 때는 다음과 같은 한계가 있습니다:

**일반적인 모델의 한계:**

- 특정 회사의 내부 용어, 프로세스, 규칙을 정확히 이해하지 못할 수 있습니다
- 특정 산업의 전문 용어나 컨텍스트를 완벽하게 파악하지 못할 수 있습니다
- 특정 형식의 출력(예: 특정 JSON 구조, 특정 스타일의 문서)을 일관되게 생성하지 못할 수 있습니다
- 특정 작업(예: 감정 분석, 개체명 인식, 번역)에 최적화되지 않았을 수 있습니다

**파인튜닝의 해결책:**

파인튜닝을 통해 모델이 특정 도메인의 데이터를 더 많이 학습하게 되면, 해당 도메인에서의 성능이 크게 향상됩니다. 모델이 특정 용어, 패턴, 스타일을 더 잘 이해하고 생성할 수 있게 됩니다.

## 2. 파인튜닝의 작동 원리

파인튜닝은 전체 모델을 처음부터 학습하는 것과는 다릅니다. 기존 모델의 가중치를 시작점으로 하여, 새로운 데이터에 맞게 가중치를 점진적으로 조정합니다. 이는 기존에 학습한 지식을 크게 망가뜨리지 않으면서 새로운 패턴을 학습하기 위함입니다. 때로는 모델의 일부 레이어만 파인튜닝하기도 합니다. 예를 들어, 하위 레이어(언어의 기본 구조를 담당)는 고정하고 상위 레이어(고수준 의미를 담당)만 조정할 수 있습니다.

## 3. 파인튜닝의 종류

### 전체 파인튜닝 (Full Fine-tuning)

모델의 모든 파라미터를 업데이트하는 방식입니다. 가장 강력하지만 계산 자원이 많이 필요하고, 과적합(Overfitting) 위험이 있습니다.

### 부분 파인튜닝 (Partial Fine-tuning)

모델의 일부 레이어만 파인튜닝하는 방식입니다. 예를 들어, 상위 레이어만 조정하고 하위 레이어는 고정할 수 있습니다. 이는 계산 비용을 줄이면서도 효과적인 결과를 얻을 수 있는 방법입니다.

### LoRA (Low-Rank Adaptation)

모델의 가중치를 직접 수정하는 대신, 작은 어댑터 행렬을 추가하여 모델의 동작을 조정하는 방식입니다. 이는 메모리 효율적이고 빠르며, 여러 작업에 대해 여러 개의 LoRA 어댑터를 만들어 전환할 수 있습니다.

### PEFT (Parameter-Efficient Fine-Tuning)

LoRA와 유사하게, 모델의 일부 파라미터만 효율적으로 조정하는 방법들을 통칭합니다. 전체 모델을 파인튜닝하는 것보다 훨씬 적은 자원으로도 좋은 성능을 얻을 수 있습니다.

## 4. 파인튜닝의 장점

특정 도메인이나 작업에 맞게 파인튜닝된 모델은 해당 작업에서 일반 모델보다 훨씬 우수한 성능을 보입니다.

파인튜닝된 모델은 외부 데이터베이스나 검색 시스템에 의존하지 않고 독립적으로 작동할 수 있습니다. 모델 자체에 지식을 내장시키므로, 민감한 정보를 외부 데이터베이스에 저장할 필요가 없습니다. 모델이 해당 정보를 학습했기 때문에, 외부 시스템에 접근하지 않고도 답변을 생성할 수 있습니다.
이는 응답 속도가 빠르고, 외부 시스템의 장애에 영향을 받지 않는다는 장점이 있습니다.

## 5. 파인튜닝의 단점

파인튜닝된 모델은 학습한 데이터에 특화되어 있어, 새로운 정보나 변경된 정보를 반영하기 어렵습니다. 새로운 정보가 생기면 다시 파인튜닝을 해야 하므로, 업데이트가 어렵고 비용이 많이 듭니다.

## 6. RAG와의 차이점

**파인튜닝**: 모델 자체를 수정하여 데이터를 모델 내부에 내장시킵니다. 모델의 가중치가 변경되므로, 모델 자체가 특정 도메인의 지식을 "기억"하게 됩니다. 그렇다보니 새로운 정보가 생기면 모델을 다시 파인튜닝해야 합니다. 학습한 데이터셋에 포함된 정보만 활용할 수 있습니다. 학습하지 않은 정보는 사용할 수 없습니다.

**RAG**: 모델은 그대로 두고, 외부 데이터베이스에서 관련 정보를 검색하여 모델에 제공합니다. 모델의 가중치는 변경되지 않으며, 매번 질문할 때마다 외부 데이터베이스를 검색합니다. 새로운 정보도 즉시 활용하며 검색 시간이 파인튜닝에 비해 상대적으로 느릴 수 있습니다.
