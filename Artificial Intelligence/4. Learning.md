## 1. 딥러닝 학습 파이프라인

### 데이터 적재 (Data Loading)

데이터 적재는 저장소에 있는 데이터를 모델이 처리할 수 있는 형태로 메모리에 불러오는 과정이다. 

대규모 데이터셋은 한 번에 모두 메모리에 올릴 수 없기 때문에, **배치(Batch)** 단위로 나누어 순차적으로 로드한다.

데이터 로더는 데이터셋에서 배치를 추출하고, 필요한 전처리를 적용하며, GPU로 전송하는 역할을 담당한다. 효율적인 데이터 로딩은 학습 속도에 직접적인 영향을 미친다. GPU가 데이터를 기다리는 시간이 길어지면 전체 학습 시간이 늘어나기 때문이다.

### 딥러닝 학습 단계

- **Forward Pass(순전파)**: 입력 데이터가 모델을 통과하며 예측값을 생성한다. 각 층의 뉴런이 입력에 가중치를 곱하고 활성화 함수를 적용하여 다음 층으로 전달한다.
**Loss 계산**: 모델의 예측값과 실제 정답을 비교하여 오차(손실)를 계산한다. 손실 함수는 모델이 얼마나 틀렸는지를 수치화한다. 
- **Backward Pass(역전파)**: 손실을 각 가중치에 대해 미분하여 그래디언트를 계산한다. 출력층에서 입력층 방향으로 거슬러 올라가며, 각 가중치가 손실에 얼마나 기여했는지 파악한다.
- **그래디언트(Gradient)**: 그래디언트는 손실 함수를 각 가중치로 편미분한 값이다. 쉽게 말해 "이 가중치를 조금 바꾸면 손실이 얼마나 변하는가?"를 나타낸다. 그래디언트가 양수면 가중치를 줄여야 손실이 감소하고, 음수면 가중치를 늘려야 손실이 감소한다.
- **가중치 업데이트**: 계산된 그래디언트를 사용하여 손실이 줄어드는 방향으로 가중치를 조금씩 변경한다. 이 과정을 옵티마이저가 담당한다.

### 학습(Training)과 추론(Inference)의 차이

- **학습(Training)**: 모델이 데이터로부터 패턴을 배우는 과정이다. 입력과 정답을 비교하여 오차를 계산하고, 이 오차를 줄이는 방향으로 모델의 가중치를 조정한다. 학습 과정에서는 그래디언트를 저장하고 역전파를 수행해야 하므로 많은 메모리와 연산이 필요하다.
- **추론(Inference)**: 학습된 모델로 새로운 데이터에 대한 예측을 수행하는 과정이다. 가중치는 고정되어 있고, 그래디언트 계산이 필요 없다. 따라서 학습보다 훨씬 적은 메모리와 연산으로 빠르게 수행할 수 있다.

## 2. 데이터 준비

### 데이터 전처리 (Preprocessing)

데이터 전처리는 원시 데이터를 모델에 적합한 형태로 변환하는 과정이다.

- **텍스트 전처리**: 소문자 변환, 특수문자 제거, 토큰화 등을 수행한다. 불필요한 노이즈를 제거하고 일관된 형식으로 만든다.  
- **정규화(Normalization)**: 데이터의 범위를 일정하게 조정한다. 정규화하면 학습이 안정적이고 빠르게 수렴한다.  
- **표준화(Standardization)**: 데이터의 평균을 0, 표준편차를 1로 만든다. 특성마다 스케일이 다른 경우 유용하다. 키(cm)와 몸무게(kg)처럼 단위가 다른 데이터를 함께 사용할 때 적용한다.  

### 데이터 정제 (Cleaning)

데이터 정제는 데이터의 품질을 높이는 과정이다. 실제 데이터에는 오류, 누락, 중복이 흔하다.

- **노이즈 제거**: 명백한 오류나 이상값을 식별하고 제거한다. 나이가 -5세로 기록된 데이터, 의미 없는 문자열 등이 여기에 해당한다.      
- **결측치 처리**: 비어 있는 값을 처리한다. 해당 데이터를 삭제하거나, 평균/중앙값으로 대체하거나, 모델로 예측하여 채울 수 있다.    
- **중복 제거**: 동일하거나 거의 동일한 데이터를 제거한다. 중복 데이터가 많으면 모델이 특정 패턴에 과적합될 수 있다.    

### 데이터 증강 (Augmentation)

데이터 증강은 기존 데이터를 변형하여 학습 데이터를 인위적으로 늘리는 기법이다. 

데이터가 부족할 때 과적합을 방지하고 모델의 일반화 성능을 높인다. 동의어 치환, 문장 순서 변경, 역번역(한→영→한) 등을 수행한다. "정말 좋은 영화였다"를 "매우 훌륭한 영화였다"로 바꿔 데이터를 늘린다. 증강은 학습 시에만 적용하고, 검증이나 테스트에는 적용하지 않는 것이 원칙이다.

## 3. 가중치와 학습

가중치(Weight)는 신경망에서 뉴런 간 연결의 강도를 나타내는 숫자다. 입력 신호에 가중치를 곱하여 다음 뉴런으로 전달한다. 가중치가 크면 해당 입력의 영향력이 강하고, 작으면 약하다. 딥러닝 모델을 학습한다는 것은 결국 최적의 가중치를 찾는 과정이다. 수십억 개의 가중치 조합 중에서 주어진 문제를 가장 잘 푸는 조합을 탐색한다. 가중치와 함께 편향(Bias)도 학습된다. 편향은 뉴런의 활성화 임계값을 조정하는 역할을 한다.

## 4. 지도 미세조정 (Supervised Fine-Tuning)

사전학습된 모델은 범용적인 언어 능력을 갖추고 있지만, 특정 작업에 최적화되어 있지 않다. 미세조정(Fine-Tuning)사전학습 모델을 특정 도메인이나 작업에 맞게 추가 학습시키는 과정이다. 미세조정의 핵심은 사전학습에서 얻은 지식을 유지하면서 새로운 능력을 추가하는 것이다. 학습률을 낮게 설정하여 기존 가중치를 크게 변경하지 않으면서 점진적으로 조정한다. 미세조정에는 상대적으로 적은 데이터로도 효과를 볼 수 있다. 사전학습에서 이미 언어의 기본 구조를 학습했기 때문이다.

### 지시 데이터셋 (Instruction Dataset)

지시 데이터셋은 사용자의 지시(Instruction)와 그에 대한 적절한 응답으로 구성된 학습 데이터다. 모델이 다양한 형태의 요청을 이해하고 따르도록 훈련하는 데 사용된다. 다양한 유형의 지시를 포함해야 모델이 범용적인 지시 수행 능력을 갖춘다. 요약, 번역, 질의응답, 코드 작성, 창작 등 다양한 작업을 커버한다.

지시 데이터셋의 구조는 일반적으로 다음과 같다:
- **지시(Instruction)**: "이 문장을 요약해줘", "영어로 번역해줘"
- **입력(Input)**: 처리할 대상 텍스트 (선택적)
- **출력(Output)**: 지시에 맞는 적절한 응답

## 5. 메모리 최적화

OOM(Out of Memory)은 GPU 메모리가 부족하여 학습이 중단되는 현상이다. 딥러닝 학습에서 자주 발생하는 문제다. 모델이 커지고, 배치 크기가 늘어나고, 시퀀스 길이가 길어질수록 메모리 사용량이 증가한다. 가장 간단한 해결책은 배치 크기를 줄이는 것이다. 한 번에 처리하는 데이터 수를 줄이면 메모리 사용량이 감소한다.

하지만 배치 크기가 너무 작으면 학습이 불안정해지고 수렴이 느려질 수 있다. 그래디언트 누적(Gradient Accumulation)을 사용하면 이 문제를 완화할 수 있다. 여러 개의 작은 배치에서 그래디언트를 계산하고 누적한 뒤, 한 번에 가중치를 업데이트한다.

## 6. 양자화 (Quantization)

양자화(Quantization)는 딥러닝 모델의 가중치와 연산을 낮은 정밀도의 숫자 형식으로 변환하는 방법이다. 주된 목적은 모델 크기를 줄이고, 메모리 사용량을 절감하며, 추론 속도를 높이는 데 있다. 일반적으로 딥러닝 모델은 FP32(32비트 부동소수점) 형식을 사용한다. 양자화를 적용하면 FP16, INT8와 같이 더 적은 비트를 사용하는 형식으로 변환할 수 있다. 비트 수가 줄어들수록 모델 크기도 비례해서 작아진다.

- **FP32 → FP16**: 32비트에서 16비트로 줄이면 모델의 크기가 절반으로 감소하고, 일반적으로 성능 손실이 거의 없다. 가장 안전하고 널리 쓰이는 방식이다.
- **FP16 → INT8**: 16비트 부동소수점을 8비트 정수로 변환하면 모델 크기가 1/4이 되지만, 수치 표현 범위가 좁아져 성능 손실이 발생할 수 있다.
- **INT8 → INT4**: 8비트에서 4비트로 낮추면 메모리 효율은 극대화되지만, 모델의 추론 정확도 저하 위험이 크다.

양자화 과정은 연속적인 부동소수점 값을 제한된 개수의 정수 값으로 매핑하는 것이므로, 미세한 값 차이가 손실되는 정보로 이어질 수 있다. 손실이 누적되면 모델 출력의 품질이 떨어질 수 있다. 양자화에 따른 성능 저하는 모델 구조, 입력 데이터, 대상 작업에 따라 다르게 나타난다. 양자화는 주로 추론 단계(inference)에서 적용하여 학습이 끝난 모델을 배포할 때 경량화하는 데 활용된다.

### 혼합 정밀도 학습(Mixed Precision Training)

혼합 정밀도 학습은 딥러닝 모델의 학습 과정에서 일부 연산을 낮은 정밀도(FP16), 나머지는 높은 정밀도(FP32)로 분리해 수행하는 최적화 기법이다. 이 방법은 메모리 사용량을 크게 줄이고, 최신 하드웨어의 빠른 연산 유닛을 활용해 학습 속도를 높인다.

#### 작동 원리:
- 대부분의 행렬 연산을 FP16으로 수행해 연산 속도와 메모리 효율을 높인다.
- **손실(loss) 계산**과 **가중치(weight) 업데이트** 등 수치적 안정성이 민감한 연산은 FP32의 높은 정밀도를 유지한다.
- 경사(gradient) 전파 시 FP16으로 계산된 gradient가 너무 작아 값이 0이 되는 “언더플로” 위험이 있기 때문에, 일반적으로 **Loss Scaling**이라는 보조 기법을 쓴다(손실 값을 크게 확대하여 gradient가 너무 작아지는 것을 방지).
