# LLM (Large Language Model)

LLM(Large Language Model, 대규모 언어 모델)은 많은 매개변수를 가진 인공지능 모델로, 인간의 언어를 이해하고 생성할 수 있는 능력을 갖춘 현대 AI의 핵심 기술입니다. ChatGPT, GPT-4, Claude, Gemini 등 우리가 일상에서 사용하는 대부분의 AI 챗봇과 언어 서비스의 기반이 되는 기술입니다.

LLM을 이해하는 가장 좋은 비유는 "도서관"입니다. 이 모델은 인터넷상의 수많은 책, 논문, 기사, 코드 등을 학습하여, 마치 인간이 수년간 책을 읽으며 언어를 습득하듯이, 단어와 문장의 패턴, 맥락, 의미를 이해하게 됩니다. 그리고 이러한 지식을 바탕으로 질문에 답하고, 글을 쓰고, 코드를 생성하며, 창의적인 작업을 수행할 수 있습니다.

---

## 1. LLM이란 무엇인가?

### 언어 모델의 기본 개념

언어 모델(Language Model)은 주어진 단어 시퀀스에서 다음 단어가 무엇일지 예측하는 확률 모델입니다. 예를 들어, "오늘 날씨가 매우"라는 문장이 주어졌을 때, 모델은 "맑다", "흐리다", "따뜻하다" 등의 단어 중에서 어떤 단어가 가장 적절한지 확률을 계산하여 예측합니다.

간단한 예시를 들어보겠습니다. "나는 매일 아침에"라는 문장을 완성한다고 가정해봅시다. 인간이라면 자연스럽게 "커피를 마신다", "운동을 한다", "신문을 읽는다" 등의 문장을 생각할 수 있습니다. 언어 모델도 마찬가지로, 학습한 수많은 문장 패턴을 바탕으로 다음 단어를 예측합니다.

### LLM의 'Large'는 무엇을 의미하는가?

LLM의 "Large"는 모델의 크기를 의미합니다. 모델이 클수록 더 복잡한 패턴을 학습할 수 있고, 더 정확하고 맥락에 맞는 언어를 생성할 수 있습니다. 하지만 동시에 더 많은 계산 자원과 비용이 필요합니다.

### LLM의 주요 능력

LLM은 다음과 같은 다양한 작업을 수행할 수 있습니다:

**1. 텍스트 생성**: 주어진 주제나 프롬프트에 맞춰 자연스러운 문장과 글을 생성합니다.

**2. 질의응답**: 사용자의 질문에 대해 학습한 지식을 바탕으로 답변을 제공합니다.

**3. 번역**: 한 언어에서 다른 언어로 텍스트를 번역합니다.

**4. 요약**: 긴 텍스트를 핵심 내용만 요약합니다.

**5. 코드 생성**: 자연어 설명을 바탕으로 프로그래밍 코드를 작성합니다.

**6. 대화**: 맥락을 이해하며 자연스러운 대화를 수행합니다.

이러한 능력들은 모두 모델이 학습한 언어 패턴을 바탕으로 다음 단어를 예측하는 기본 원리에서 나옵니다.

## 2. LLM의 작동 원리: 토큰화와 예측

### 토큰화 (Tokenization)

LLM이 텍스트를 처리하는 첫 번째 단계는 **토큰화(Tokenization)**입니다. 토큰화는 텍스트를 작은 단위로 나누는 과정입니다. 이 단위는 단어일 수도 있고, 단어의 일부일 수도 있으며, 문자일 수도 있습니다.

예를 들어, "안녕하세요"라는 텍스트를 토큰화하면:

- 단어 단위: ["안녕하세요"]
- 문자 단위: ["안", "녕", "하", "세", "요"]
- 서브워드 단위: ["안녕", "하세요"]

실제 LLM에서는 주로 **서브워드(Subword)** 토큰화를 사용합니다. 이렇게 하면 학습하지 못한 단어(Out-of-Vocabulary)를 만났을 때도, 작은 토큰들의 조합으로 처리할 수 있기 때문입니다.

### 임베딩 (Embedding)

토큰화된 단어들은 숫자 벡터로 변환됩니다. 이 과정을 **임베딩(Embedding)**이라고 합니다. 각 단어는 수백 차원의 벡터로 표현되며, 이 벡터는 단어의 의미와 문맥을 담고 있습니다.

임베딩의 마법은 유사한 의미를 가진 단어들이 공간상에서 가까운 위치에 배치된다는 것입니다. 예를 들어, "고양이"와 "강아지"의 임베딩 벡터는 "컴퓨터"의 임베딩 벡터보다 서로 가까이 있을 것입니다.

1. **입력 처리**: 사용자가 입력한 텍스트를 토큰화하고 임베딩 벡터로 변환
2. **맥락 이해**: 트랜스포머 아키텍처를 통해 모든 토큰 간의 관계와 맥락을 이해
3. **확률 계산**: 다음에 올 수 있는 모든 가능한 토큰에 대한 확률을 계산
4. **토큰 선택**: 확률이 가장 높은 토큰을 선택하거나, 확률 분포에 따라 샘플링
5. **반복**: 선택된 토큰을 문장에 추가하고, 다시 다음 토큰을 예측하는 과정을 반복

### 어텐션 메커니즘 (Attention Mechanism)

LLM이 문맥을 이해하는 핵심 메커니즘은 **어텐션(Attention)**입니다. 어텐션은 문장의 각 단어가 다른 단어들과 얼마나 관련이 있는지를 계산하여, 중요한 정보에 더 집중할 수 있게 해줍니다.

예를 들어, "그는 학교에 가서 친구를 만났다"라는 문장에서, "만났다"라는 동사를 이해하려면 "그는"과 "친구를"에 주목해야 합니다. 어텐션 메커니즘은 이러한 관계를 자동으로 학습하여, 문맥을 올바르게 이해할 수 있게 합니다.

## 3. LLM의 학습 과정

### 사전 학습 (Pre-training)

LLM의 학습은 두 단계로 나뉩니다. 첫 번째 단계는 **사전 학습(Pre-training)**입니다. 이 단계에서 모델은 인터넷상의 방대한 텍스트 데이터를 학습합니다. 목표는 언어의 일반적인 패턴, 문법, 사실 관계, 맥락 등을 이해하는 것입니다.

사전 학습은 주로 **언어 모델링(Language Modeling)** 작업을 통해 이루어집니다. 모델에게 문장의 일부를 보여주고, 다음 단어를 예측하도록 학습시킵니다. 이 과정을 수조 개의 문장에 대해 반복하면서, 모델은 점차 언어의 패턴을 이해하게 됩니다.

예를 들어, "파리는 프랑스의 수도이다"라는 문장이 주어졌을 때, 모델은 "파리는" 다음에 "프랑스의"가 오는 패턴을 학습하고, 동시에 "파리"와 "프랑스"가 관련이 있다는 사실도 암묵적으로 학습합니다.

### 파인튜닝 (Fine-tuning)

사전 학습이 완료된 모델은 범용적인 언어 이해 능력을 갖추지만, 특정 작업(예: 대화, 질의응답, 코드 생성)에 최적화되지는 않았습니다. 따라서 **파인튜닝(Fine-tuning)** 단계에서 특정 작업에 맞는 데이터를 추가로 학습시킵니다.

예를 들어, 대화형 챗봇으로 만들기 위해서는 대화 형식의 데이터(질문-답변 쌍 등)를 추가로 학습시킵니다. 코드 생성에 특화시키려면 코드와 설명이 함께 있는 데이터를 학습시킵니다.

최근의 LLM들은 **지시 학습(Instruction Tuning)**을 통해 더욱 개선됩니다. 이는 모델에게 다양한 형태의 지시나 명령을 따르도록 학습시키는 것입니다. 예를 들어:

- "이 텍스트를 요약해줘"
- "다음 문장을 영어로 번역해줘"
- "이 코드의 버그를 찾아줘"

### 학습의 비용과 시간

- **데이터 수집**: 인터넷에서 수백 테라바이트의 텍스트 데이터 수집 및 정제
- **하드웨어**: 수천 개의 고성능 GPU와 대규모 컴퓨팅 클러스터
- **시간**: 수 주에서 수 개월의 학습 시간
- **비용**: 수백만 달러에서 수천만 달러에 이르는 학습 비용

이러한 이유로 대부분의 기업이나 개인은 처음부터 LLM을 학습시키기보다는, 이미 학습된 모델을 활용하거나 파인튜닝하는 방식을 사용합니다.

## 4. 프롬프트 엔지니어링 (Prompt Engineering)

**프롬프트(Prompt)**는 사용자가 LLM에 입력하는 텍스트 지시입니다. LLM의 성능은 프롬프트의 질에 크게 좌우됩니다. 같은 모델이라도 잘 작성된 프롬프트는 훨씬 좋은 결과를 만들어내는 반면, 불명확한 프롬프트는 만족스럽지 못한 결과를 만들 수 있습니다.

예를 들어, 단순히 "요약해줘"라고 하기보다는, "다음 텍스트를 3문장으로 요약해줘. 핵심 내용만 포함하고 간결하게 작성해줘"라고 하면 훨씬 원하는 결과를 얻을 수 있습니다.

### 효과적인 프롬프트 작성법

**1. 명확한 지시**: 모호한 표현보다 구체적인 지시를 사용합니다.

- 나쁜 예: "이것에 대해 설명해줘"
- 좋은 예: "이 코드 블록의 기능을 3가지로 나누어 설명하고, 각각의 역할을 설명해줘"

**2. 컨텍스트 제공**: 필요한 배경 정보를 포함합니다.

- 나쁜 예: "번역해줘"
- 좋은 예: "다음 영어 문장을 자연스러운 한국어로 번역해줘. 비즈니스 문서의 일부입니다."

**3. 출력 형식 지정**: 원하는 출력 형식을 명시합니다.

- 나쁜 예: "리스트를 만들어줘"
- 좋은 예: "다음 항목들을 마크다운 형식의 불릿 리스트로 정리해줘"

**4. 예시 제공 (Few-shot Learning)**: 원하는 출력 예시를 함께 제공하면 더 정확한 결과를 얻을 수 있습니다.

**5. 단계별 접근**: 복잡한 작업은 여러 단계로 나누어 요청합니다.

## 5. LLM의 한계와 도전 과제

### 환각 (Hallucination)

LLM의 가장 큰 문제 중 하나는 **환각(Hallucination)** 현상입니다. 이는 모델이 실제로는 존재하지 않거나 잘못된 정보를 자신 있게 생성하는 것입니다. 모델은 학습한 데이터의 패턴을 기반으로 텍스트를 생성하지만, 사실 여부를 확인하지 않기 때문에 가끔 잘못된 정보를 만들어냅니다.

예를 들어, 모델이 "플라톤은 2020년에 노벨 문학상을 수상했다"와 같은 완전히 잘못된 정보를 생성할 수 있습니다. 이러한 이유로 LLM의 출력은 항상 검증이 필요하며, 중요한 결정에는 단독으로 사용하기보다는 인간의 검토가 필요합니다.

### 편향 (Bias)

LLM은 학습 데이터에 포함된 편향을 그대로 반영할 수 있습니다. 만약 학습 데이터에 특정 인종, 성별, 종교 등에 대한 편견이 포함되어 있다면, 모델의 출력에도 이러한 편견이 나타날 수 있습니다. 이를 해결하기 위해서는 학습 데이터를 다양하고 공정하게 선별합니다.

### 개인정보 보호

LLM을 학습시키기 위해 대량의 인터넷 데이터를 사용하므로, 학습 데이터에 개인정보가 포함될 수 있는 우려가 있습니다. 모델이 학습한 내용에서 개인정보를 완전히 제거하는 것은 어렵기 때문에, 개인정보 보호와 데이터 사용 사이의 균형이 중요한 이슈입니다.
