# 선형대수학 (Linear Algebra)

선형대수학은 인공지능, 특히 딥러닝 모델이 데이터를 구조화하고 조작하는 방식의 핵심적인 수학적 언어입니다. AI에서 다루는 모든 데이터는 형태로 표현되며, 모델의 학습 과정은 이러한 구조에 대한 끊임없는 선형 변환(행렬 곱셈)으로 구성됩니다.

일상적인 비유로 설명하자면, 선형대수학은 컴퓨터가 세상을 이해하기 위해 사용하는 "단어책"과 같은 역할을 합니다. 우리가 "고양이"라는 단어로 고양이를 표현하듯이, 컴퓨터는 "고양이"를 [0.2, 0.8, 0.1, ...] 같은 숫자들의 배열, 즉 벡터로 표현합니다. 그리고 이러한 벡터들을 모아서 행렬로 만들고, 행렬 간의 연산을 통해 의미 있는 정보를 추출하고 변환합니다.

---

## 1. 벡터 (Vector): 데이터의 기본 단위

### 벡터의 개념

벡터는 일반적으로 물리학에서는 "방향과 크기를 가진 화살표"로 설명되지만, AI와 데이터 과학에서는 조금 다른 의미로 사용됩니다. 벡터는 숫자들의 순서 있는 배열입니다. 이 배열의 각 숫자는 특정한 의미를 가진 "특징(Feature)" 또는 "속성(Attribute)"을 나타냅니다.

예를 들어, 온라인 쇼핑몰에서 한 명의 고객을 데이터로 표현한다고 가정해봅시다. 이 고객의 정보는 다음과 같습니다:

- 나이: 35세
- 월 소득: 500만원
- 지난 달 구매 횟수: 10회

이 세 가지 정보를 하나의 벡터로 표현하면 `[35, 5000, 10]`이 됩니다. 여기서 첫 번째 숫자 35는 나이를, 두 번째 숫자 5000은 소득을, 세 번째 숫자 10은 구매 횟수를 의미합니다. 이처럼 벡터는 여러 가지 특징을 하나의 묶음으로 표현하는 수학적 도구입니다.

### 차원(Dimension)의 의미

벡터의 차원은 벡터 안에 포함된 숫자의 개수, 즉 특징의 개수를 의미합니다. 위의 고객 예시에서 벡터는 3개의 숫자로 구성되어 있으므로 "3차원 벡터"라고 부릅니다.

차원이 높아질수록 더 많은 정보를 담을 수 있지만, 동시에 계산이 복잡해지고 시각화하기 어려워집니다. 2차원 벡터는 평면 그래프에 점으로 표현할 수 있고, 3차원 벡터는 3D 공간에 점으로 표현할 수 있지만, 4차원 이상부터는 우리의 직관적 이해가 어려워집니다. 하지만 컴퓨터는 수천, 수만 차원의 벡터도 문제없이 다룰 수 있습니다.

### AI에서 벡터의 활용

AI 분야에서 벡터는 다양한 방식으로 활용됩니다:

**자연어 처리(NLP)에서의 벡터**: 단어의 의미를 숫자로 표현한 "임베딩(Embedding)" 벡터를 사용합니다. 예를 들어 "고양이"와 "강아지"는 서로 가까운 벡터 값으로 표현되어 의미적으로 유사한 것으로 인식되고, "고양이"와 "컴퓨터"는 멀리 떨어진 벡터 값으로 표현되어 서로 다른 의미를 가진 것으로 인식됩니다.

**이미지 처리에서의 벡터**: 이미지의 각 픽셀의 색상 정보를 숫자로 변환하여 하나의 긴 벡터로 만듭니다. 100×100 크기의 흑백 이미지는 10,000개의 픽셀로 구성되므로, 10,000차원의 벡터로 표현됩니다.

**신경망 내에서의 벡터**: 딥러닝 모델의 각 층(Layer) 사이를 지나가는 정보는 모두 벡터의 형태입니다. 입력 데이터가 첫 번째 층을 통과하면서 변형되고, 이 변형된 벡터가 다음 층으로 전달되며, 이 과정이 반복되면서 최종적으로 예측 결과가 나옵니다.

```python
import numpy as np

# 고객 데이터를 벡터로 표현
customer = np.array([35, 5000, 10])
print(f"고객 벡터: {customer}")
print(f"벡터의 차원: {customer.shape}")

# 두 고객 간의 거리 계산 (유클리드 거리)
customer1 = np.array([35, 5000, 10])
customer2 = np.array([28, 4000, 5])
distance = np.linalg.norm(customer1 - customer2)
print(f"두 고객 간의 거리: {distance:.2f}")
```

---

## 2. 행렬 (Matrix): 데이터셋의 구조화

### 행렬의 개념

행렬은 벡터들을 직사각형 격자 형태로 배열한 것입니다. 쉽게 말해, 여러 개의 벡터를 나란히 세워놓은 것이 행렬이라고 생각하면 됩니다.

행렬의 구조를 이해하는 것이 매우 중요합니다:

- **행(Row)**: 행렬의 가로 줄로, 일반적으로 하나의 데이터 관측치를 나타냅니다. 예를 들어, 한 명의 고객, 한 장의 이미지, 하나의 문장 등이 하나의 행이 됩니다.
- **열(Column)**: 행렬의 세로 줄로, 데이터의 특정 특징(Feature)을 나타냅니다. 예를 들어, 나이, 소득, 구매 횟수 등이 각각 하나의 열이 됩니다.

만약 고객 5명의 데이터가 있고, 각 고객은 나이, 소득, 구매 횟수 세 가지 특징을 가진다면, 이를 5행 3열의 행렬로 표현할 수 있습니다. 행렬의 각 행은 한 명의 고객을 나타내고, 각 열은 특정 특징을 나타냅니다.

### 행렬의 구조적 의미

행렬을 사용하는 가장 큰 이유는 대량의 데이터를 체계적으로 조직화할 수 있기 때문입니다. 벡터 하나는 하나의 데이터 포인트만 표현할 수 있지만, 행렬은 수백만 개의 데이터 포인트를 하나의 구조물 안에 담을 수 있습니다.

또한 행렬로 데이터를 구조화하면, 컴퓨터가 효율적으로 계산을 수행할 수 있습니다. 현대의 GPU(그래픽 처리 장치)는 수천 개의 연산을 동시에 수행할 수 있는데, 이러한 병렬 처리가 가능한 이유는 데이터가 행렬 형태로 정리되어 있기 때문입니다.

```python
import numpy as np

# 5명의 고객 데이터를 행렬로 표현
# 각 행: 한 명의 고객 (나이, 소득, 구매 횟수)
customers = np.array([
    [35, 5000, 10],
    [28, 4000, 5],
    [42, 6000, 15],
    [31, 4500, 8],
    [39, 5500, 12]
])

print("고객 데이터 행렬:")
print(customers)
print(f"\n행렬 크기: {customers.shape}")  # (5, 3) = 5행 3열
print(f"첫 번째 고객 (첫 번째 행): {customers[0]}")
print(f"모든 고객의 나이 (첫 번째 열): {customers[:, 0]}")
```

---

## 3. 행렬 곱셈과 선형 변환

### 선형 변환이란?

행렬의 가장 중요한 역할은 선형 변환(Linear Transformation)을 수행하는 것입니다. 선형 변환은 입력 데이터를 다른 형태의 데이터로 변환하는 수학적 연산입니다.

간단한 비유를 들어보겠습니다. 행렬 곱셈은 마치 "번역기"와 같은 역할을 합니다. 영어 문장(입력 벡터)을 한국어 문장(출력 벡터)으로 번역하는 것처럼, 행렬은 데이터를 한 표현 공간에서 다른 표현 공간으로 변환합니다.

### 딥러닝에서의 행렬 곱셈

딥러닝 모델의 핵심 연산은 다음과 같은 형태입니다:
**출력 = 입력 × 가중치 행렬**

이 과정에서 두 가지 중요한 일이 일어납니다:

**1. 가중치 적용**: 가중치 행렬의 각 숫자는 입력 데이터의 각 특징에 얼마나 중요도를 부여할지를 결정합니다. 예를 들어, 고객의 나이보다 소득이 더 중요하다고 모델이 학습했다면, 소득에 해당하는 가중치 값이 더 크게 설정됩니다.

**2. 차원 변환**: 행렬 곱셈을 통해 데이터의 차원을 줄이거나(압축), 늘리거나(확장) 할 수 있습니다. 차원을 줄이는 것은 불필요한 정보를 제거하고 핵심 특징만 추출하는 과정이고, 차원을 늘리는 것은 더 세밀한 특징 공간으로 데이터를 확장하는 과정입니다.

### 실제 동작 원리

예를 들어, 3차원 입력 벡터(나이, 소득, 구매 횟수)를 2차원 출력 벡터로 변환하는 상황을 생각해봅시다. 이는 "고객 분류 점수"와 "구매 가능성 점수" 두 가지로 정보를 압축하는 것입니다. 이 변환은 3×2 크기의 가중치 행렬을 사용하여 수행됩니다.

행렬 곱셈을 통해 3개의 특징이 2개의 새로운 특징으로 변환되며, 이 과정에서 모델이 학습한 패턴과 규칙이 적용됩니다. 이렇게 변환된 데이터는 다음 층으로 전달되어 더 복잡한 계산에 사용됩니다.

```python
import numpy as np

# 입력 데이터: 3차원 벡터 (나이, 소득, 구매 횟수)
input_vector = np.array([[35, 5000, 10]])

# 가중치 행렬: 3×2 크기 (3개 입력 → 2개 출력)
weight_matrix = np.array([
    [0.1, 0.3],   # 나이에 대한 가중치
    [0.5, 0.2],   # 소득에 대한 가중치
    [0.2, 0.4]    # 구매 횟수에 대한 가중치
])

# 행렬 곱셈을 통한 선형 변환
output = np.dot(input_vector, weight_matrix)
print(f"입력 벡터: {input_vector[0]}")
print(f"출력 벡터: {output[0]}")
print(f"입력 차원: 3 → 출력 차원: 2")
```

---

선형대수학이 AI에서 중요한 이유는 모든 종류의 데이터를 벡터와 행렬로 표현할 수 있기 때문입니다

- **이미지**: 각 픽셀의 색상 값을 벡터로 변환
- **텍스트**: 단어나 문장을 의미 벡터(임베딩)로 변환
- **음성**: 음성 신호를 주파수 성분의 벡터로 변환

딥러닝 모델의 학습은 본질적으로 "가중치 행렬을 조정하는 과정"입니다. 모델은 입력 데이터와 정답을 비교하면서, 가중치 행렬의 각 숫자를 조금씩 수정하여 더 정확한 예측을 하도록 개선합니다. 이 모든 과정이 행렬 연산으로 이루어집니다.

선형대수학은 AI에게 데이터를 다루는 '언어'를 제공하며, 행렬 곱셈은 모델이 세상을 인식하고 학습하는 '계산 엔진' 역할을 수행합니다. 벡터와 행렬을 이해하면, 딥러닝 모델이 내부적으로 어떻게 동작하는지 그 원리를 파악할 수 있게 됩니다.
