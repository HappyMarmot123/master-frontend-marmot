## 1. 성능 평가 파이프라인

LLM의 성능을 체계적으로 평가하려면 **평가 파이프라인**이 필요하다. 일회성 테스트가 아닌, 반복 가능하고 일관된 평가 체계를 구축해야 모델 개선 여부를 정확히 파악할 수 있다. 평가 파이프라인의 주요 구성 요소는 다음과 같다.

- **평가 데이터셋**: 모델 성능을 측정할 입력-출력 쌍의 모음이다. 다양한 유형의 질문과 기대 답변을 포함해야 한다. 실제 사용 패턴을 반영하고 엣지 케이스도 포함해야 한다.    
- **평가 지표**: 모델 출력의 품질을 수치화하는 기준이다. BLEU, ROUGE 같은 자동 지표와 인간 평가 점수가 있다.    
- **평가 실행 환경**: 동일한 조건에서 평가를 수행할 수 있는 환경이다. 모델 버전, 프롬프트, 하이퍼파라미터 등을 고정하여 재현 가능한 결과를 얻는다.    
- **결과 저장 및 비교**: 평가 결과를 기록하고 이전 버전과 비교한다. 시간에 따른 성능 변화를 추적한다.    

## 2. 평가 지표 BLEU(Bilingual Evaluation Understudy)

BLEU 스코어는 기계 번역을 비롯해 다양한 생성형 AI의 성능을 정량적으로 평가할 때 널리 사용된다. BLEU의 핵심은 모델이 생성한 출력이 참조 답변과 얼만큼 n-gram 수준에서 유사한가를 수치로 나타내는 것이다.

이 지표에서 n-gram이란 연속된 n개의 단어 묶음을 의미한다. 예를 들어 "나는 학교에 간다"라는 문장에서 1-gram은 ["나는", "학교에", "간다"]처럼 단어 하나씩이고, 2-gram은 ["나는 학교에", "학교에 간다"]처럼 두 단어씩 묶은 것이다.

BLEU 스코어는 다음과 같이 계산된다. 먼저 모델이 생성한 출력에서 gram을 뽑아낸다. 그런 뒤 각각의 n-gram이 참조 정답에 몇 번이나 등장하는지 확인한다. 이를 바탕으로 일치율(precision), 즉 생성 결과 중 참조 답변에도 나타나는 n-gram의 비율을 구한다. 만약 모델 출력이 참조보다 지나치게 짧으면 점수가 인위적으로 높아질 수 있으므로, 짧은 출력에 불이익을 곱한다. 마지막으로 여러 n-gram의 일치율을 하나의 값으로 결합한다.

## 3. LLM 캐시

LLM은 대규모 연산, 특히 GPU 연산 자원을 많이 요구하기 때문에, 동일한 요청에 대해 반복적으로 LLM을 호출하지 않고 결과를 캐시하는 것이 매우 중요하다. LLM 캐시는 사용자로부터 들어온 요청과 그에 대한 LLM의 생성 결과를 저장해두었다가, 동일한(혹은 유사한) 요청이 들어올 때 이미 저장된 결과를 즉시 반환한다.

### 일치 캐시 (Exact Match Cache)

일치 캐시는 입력된 요청과 이전에 저장된 요청이 완전히 동일할 때에만 캐시된 결과를 반환하는 방식이다. 이 방식은 주로 해시(hash) 구조를 이용해 구현하며, 절차가 간단하다는 장점이 있다. 일치 캐시는 구현이 간편하고 결과의 정확성이 높다는 장점이 있지만, 요청에 미세한 차이가 있을 때마다 캐시 미스가 발생하여 캐시의 효율성이 떨어질 수 있다.

### 유사 검색 캐시 (Semantic Cache)

유사 검색 캐시는 요청이 정확히 동일하지 않더라도 의미적으로 유사한 경우에 캐시된 결과를 제공하는 방식이다. 입력된 요청을 임베딩 벡터로 변환한 뒤, 이미 저장된 요청들의 임베딩과 비교하여 유사도가 일정 임계값 이상인 경우에 기존 결과를 재사용한다. 이러한 방식은 다양한 표현에도 유연하게 대응할 수 있어 캐시 적중률을 크게 높인다. 다만, 요청 임베딩을 계산해야 하고, 두 요청이 충분히 비슷하다고 간주할 임계값을 신중하게 설정해야 한다는 점, 그리고 가끔은 의미가 다르지만 유사하다고 판단되는 잘못된 매칭이 발생할 수도 있다는 점은 단점으로 작용할 수 있다.

캐시를 설계할 때는 캐시 키를 무엇으로 정할지 우선적으로 고민해야 한다. 예를 들어, 프롬프트만 캐시 키로 삼을 수도 있고, 시스템 메시지나 기타 옵션까지 포함할 수도 있다. 또한, TTL(Time-To-Live), 각 캐시 항목의 유효 기간을 설정하는 것도 중요하다. 예를 들어 날씨나 최신 뉴스처럼 자주 변하는 정보의 경우에는 짧은 TTL을 적용해 결과가 오래 남지 않도록 해야 한다. 그리고 모델이 업데이트되거나 프롬프트가 바뀌었을 때는 관련 캐시를 무효화하여, 최신 정보에 맞지 않는 결과가 반환되지 않도록 관리해야 한다.

## 4. 데이터 검증 (Guardrails)

LLM은 유해한 콘텐츠 생성, 개인정보 노출, 환각 현상 등 여러 가지 위험이 존재한다. 이러한 위험을 방지하기 위해 프로덕션 환경에서 LLM을 사용할 때는 반드시 입출력을 검증하고 제어하는 장치가 필요하다. 이를 Guardrails라고 하며, LLM의 입력과 출력을 모니터링하여 문제가 발생할 경우 차단하거나 수정하는 역할을 수행한다.
