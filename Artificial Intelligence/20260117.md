LLM은 기술적으로 딥러닝에 기반을 둔다.
딥러닝은 표 형태의 정형 데이터뿐만 아니라 텍스트와 이미지 같은 비정형 데이터에서도 뛰어난 패턴 인식 성능을 보인다.
NLP 자연어 처리 분야에 속하며 다음에 올 단어를 예측하면서 문장을 하나씩 생성한다. 이를 언어 모델이라고 한다.

트랜스포머 아키텍처 - 기계 번역 성능을 높임
트랜스포머는 맥락을 모두 참조하는 어텐션 연산을 통해 다음 단어를 예측한다.
트랜스포머는 많은 연산량을 필요로 하지만 성능이 좋고 벙렬 처리로 학습 속도를 높인다.

트랜스포머 아키텍처를 이용한 모델은 크게 세가지 그룹이 존재한다.
BERT, GPT, T5 각 장단점이 존재함.

딥러닝의 문제 해결법

1. 문제의 유형(자연어,이미지 처리)에 따라 사용되는 모델 준비
2. 풀고자 하는 문제의 학습 데이터 준비
3. 학습 데이터를 반복적으로 모델에 입력
   여기서 머신러닝은 사람이 직접 데이터의 특징을 추출한다면, 딥러닝은 특징 추출과 분류를 함께 한다.

컴퓨터가 이해할 수 있게 데이터의 의미와 특징을 포착해 숫자로 표현한 것이 임베딩
임베딩은 거리를 계산할 수 있어 다음과 같은 작업에 활용된다

1. 검색 및 추천: 검색과 관련이 있는 상품을 추천한다
2. 클러스터링 및 분류: 유사하거나 관련 있는 데이터를 하나로 묶는다
3. 이상치 감지: 거리가 먼 데이터는 이상치로 볼 수 있다

임베딩 과정

1. 텍스트를 적절하게 잘라 숫자형 아이디를 부여하는 토큰화 수행

딥러닝 분야는 문제를 해결한 과정에서 얻은 정보를 다른 문제를 풀 때 사용하는데 이를 전이학습(사전학습+미세조정) 이라고 부른다.

딥러닝 모델 크기는 커지는 추세이기 때문에 학습과 추론에서 많은 연산을 요구한다.
딥러닝 모델은 행렬 곱셈 연산을 처리하는데, 이를 병렬로 처리하게 특화된 장치가 GPU 이다.

LLM 환각 현상을 줄이는 검색 증강 생성 (RAG)

멀티모달: 더 다양한 형식 데이터를 입력,출력
에이전트: 계획, 의사결정, 행동수행

지도 미세 조정과 지시 데이터셋

딥러닝 모델 학습/추론에서 잦은 OOM(Out of Memory) 최적화
모델 용량을 줄이는 양자화 방법
양자화를 수행하면 모델 용량은 줄지만 정보손실로 모델 성능 저하 가능성

성능 평가 파이프라인
bleu 스코어 측정하는법

LLM 오케스트레이션 도구는 UI, 임베딩 모델, 벡터DB 등 LLM 앱의 구성요소를 연결하는 프레임워크로 대표적으로 LangChain, 라마인덱스가 있다.

찾고자 하는 쿼리의 임베딩 벡터와 가장 가까운 벡터를 DB에서 찾는데, 이때 일반적으로 유클리드 거리나 코사인 유사도를 활용해 거리를 계산한다.

LLM 캐시는 LLM 추론을 수행할 때 사용자 요청과 생성 결과를 기록하고 이후에 동일한 요청이 들어오면 응답한다. 일치캐시와 유사검색캐시가 존재한다.

데이터 검증으로 Nemo-Guardrails 라이브러리를 사용해보자
데이터 로깅으로 W&B 또는 MLflow를 사용해보자

검색 성능을 높이는 방법
바이 인코더는 독립적인 문장 임베딩 사이 유사도를 가벼운 벡터 연산을 통해 빠른 검색이 가능하므로 1차적인 필터링으로 사용한다.
교차 인코더는 비교하려는 두 문장을 직접 입력으로 비교하므로 유사도를 더 정확하게 비교함. 계산량이 많아도 1차 필터링된 상태에서 사용하므로 더 높은 정확도를 제공할 수 있다.

좋은 임베딩 모델이라면 검색 쿼리와 관련 있는 문서가 유사도가 높게 나온다.
임베딩 모델을 KLUE의 MRC 데이터셋으로 추가 학습시켜 성능 향상이 가능하다.
